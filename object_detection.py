# -*- coding: utf-8 -*-
"""object detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10U1rSCg_Pme_fJ15bfQovZPOuPrf-QCh
"""



"""In this example we are going to look deep in to the object detection and image segmentation , so there are various ideas introducted in the object detection example the goal of this section is to look in to those parameters. """

import keras 
import tensorflow as tf 
from keras.datasets import mnist
import matplotlib.pyplot as plt
# tf.compat.v1.enable_eager_execution()
# tf.config.run_functions_eagerly(True)
from keras.utils import to_categorical
from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense
from keras.optimizers import SGD
from sklearn.preprocessing import OneHotEncoder
from tensorflow.keras import layers
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras.models import Sequential

"""##MNIST

"""



(trainX, trainy), (testX, testy) = mnist.load_data()

trainX.shape
plt.imshow(trainX[1,:,:])

def display_image(rows,cols):
  rows=rows
  cols=cols
  size=rows*cols
  fig, axs = plt.subplots(rows,cols)
  fig.set_size_inches(5,5)
  count=0
  for row in range(rows):
    for col in range(cols):
      axs[row, col].imshow(trainX[count,:,:])
      axs[row, col].set_xmargin(3)
      axs[row, col].set_ymargin(10)
      #disabling the tickers 
      axs[row, col].tick_params(axis="both",which='both',bottom=False,
                                left=False,top=False,labelbottom=False,labelleft=False)
      #setting title 
      # axs[row, col].set_title(path_array[1].split("/")[-1])
      count=count+1
  plt.show() 

display_image(5,5)

#this is how the intersection work
'''we use the idea of the intersection to find the right object.'''

three=plt.imshow(trainX[7,:,:])
three_=plt.imshow(trainX[10,:,:])

substraction =trainX[10,:,:]/255-trainX[7,:,:]/255-trainX[12,:,:]/255
plt.imshow(substraction)



"""Lets start thinking about an image segmentation example, in this example we are going to train a network to segment a dog image. 

<ul>Questions
<li>What is this separableconv2d?
<li
"""

'''building the u net '''

 previous_block_activation=x

for filter in [64,128,256]:
  x = layers.Activation("relu")(x)
  x = layers.SeparableConv2D(filters, 3, padding="same")(x)
  x = layers.BatchNormalization()(x)

  x = layers.Activation("relu")(x)
  x = layers.SeparableConv2D(filters, 3, padding="same")(x)
  x = layers.BatchNormalization()(x)

  x = layers.MaxPooling2D(3, strides=2, padding="same")(x)

    # project the residual 
  residual = layers.Conv2D(filters, 1, strides=2, padding="same")(previous_block_activation)

  x= layers.add([x+residual])  # Add back residual
  previous_block_activation=x # Set aside next residual



"""## C10"""



"""Image pre processing is an important component , in this part we are going to look into some of the techniques that can be used in the processing of image.

"""

'''
So there are various methodtf.keras.datasets.cifar10.load_data()
s for inputting the image. In this example we are going
 to start with the dataset object from the tensorflow to do this.

 In this case we are going use the cidac dataset.
'''

(x_train, y_train), (x_test, y_test)=tf.keras.datasets.cifar10.load_data()

# binary encode
onehot_encoder = OneHotEncoder(sparse=False)
# integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)
onehot_encoded = onehot_encoder.fit_transform(y_train)
print(onehot_encoded)

# define cnn model
def define_model():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dense(10, activation='softmax'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
	return model

model_seq=define_model()

keras.utils.plot_model(model_seq, "my_first_model_with_shape_info.png", show_shapes=True)

img_width=32
img_height=32
# Inputs to the model
input_img = layers.Input(
    shape=(img_width, img_height, 3), name="image"
)
labels = layers.Input(name="label", shape=(10))

# First conv block
x = layers.Conv2D(
    32,
    (3,3),
    activation="relu",
    kernel_initializer="he_normal",
    padding="same",
    input_shape=(32, 32, 3),
    name="Conv1",
)(input_img)
x = layers.MaxPooling2D((2, 2), name="pool1")(x)

# Second conv block
x = layers.Conv2D(
    64,
    (3,3),
    activation="relu",
    kernel_initializer="he_normal",
    padding="same",
    name="Conv2",
)(x)
x = layers.MaxPooling2D((2,2), name="pool2")(x)
# Second conv block
x = layers.Conv2D(
    64,
    (3,3),
    activation="relu",
    kernel_initializer="he_normal",
    padding="same",
    name="Conv3",
)(x)


# We have used two max pool with pool size and strides 2.
# Hence, downsampled feature maps are 4x smaller. The number of
# filters in the last layer is 64. Reshape accordingly before
# passing the output to the RNN part of the model
x = layers.Flatten()(x)
x = layers.Dense(64, activation="relu", name="dense1")(x)
x = layers.Dense(32, activation="relu", name="dense2")(x)
x = layers.Dropout(0.2)(x)
output=layers.Dense(10, activation="relu", name="dense3")(x)
# Define the model
model = keras.models.Model(
    inputs=[input_img,labels], outputs=output, name="ocr_model_v1"
)

# Optimizer
opt = SGD(lr=0.001, momentum=0.9)
# Compile the model and return
model.compile(optimizer=opt,loss='categorical_crossentropy')


model.summary()

keras.utils.plot_model(model, "my_first_model_with_shape_info.png", show_shapes=True)

def encode_single_sample(img, label):
    # # 1. Read image
    # img = tf.io.read_file(img_path)
    # # 2. Decode and convert to grayscale
    # img = tf.io.decode_png(img, channels=1)
    # 3. Convert to float32 in [0, 1] range
    img = tf.image.convert_image_dtype(img, tf.float32)
    # 4. Resize to the desired size
    img = tf.image.resize(img, [img_height, img_width])
    # 7. Return a dict as our model is expecting two inputs
    return {"image": img, "label": label}

batch_size=20
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, onehot_encoded)).batch(batch_size)

tf.trainable_variables()

trainY = to_categorical(y_train)

epochs = 100
early_stopping_patience = 10

# Train the model
# scale pixels
def prep_pixels(train, test):
	# convert from integers to floats
	train_norm = train.astype('float32')
	test_norm = test.astype('float32')
	# normalize to range 0-1
	train_norm = train_norm / 255.0
	test_norm = test_norm / 255.0
	# return normalized images
	return train_norm, test_norm
trainX, testX = prep_pixels(x_train, x_test)

history = model.fit(train_dataset,
  batch_size=100,
  epochs=epochs
)
trainX.shape